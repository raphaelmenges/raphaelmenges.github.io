---
---
References
==========

@article{menges2019iue,
 author = {Menges, Raphael and Kumar, Chandan and Staab, Steffen},
 title = {Improving User Experience of Eye Tracking-Based Interaction: Introspecting and Adapting Interfaces},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {November 2019},
 volume = {26},
 number = {6},
 month = nov,
 year = {2019},
 issn = {1073-0516},
 pages = {37:1--37:46},
 articleno = {37},
 numpages = {46},
 url = {http://doi.acm.org/10.1145/3338844},
 doi = {10.1145/3338844},
 acmid = {3338844},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Eye tracking, GazeTheWeb, Web accessibility, gaze interaction experience, gaze-based emulation, gaze-controlled interface, interface semantics, introspection},
 abstract = {Eye tracking systems have greatly improved in recent years, being a viable and affordable option as digital communication channel, especially for people lacking fine motor skills. Using eye tracking as an input method is challenging due to accuracy and ambiguity issues, and therefore research in eye gaze interaction is mainly focused on better pointing and typing methods. However, these methods eventually need to be assimilated to enable users to control application interfaces. A common approach to employ eye tracking for controlling application interfaces is to emulate mouse and keyboard functionality. We argue that the emulation approach incurs unnecessary interaction and visual overhead for users, aggravating the entire experience of gaze-based computer access. We discuss how the knowledge about the interface semantics can help reducing the interaction and visual overhead to improve the user experience. Thus, we propose the efficient introspection of interfaces to retrieve the interface semantics and adapt the interaction with eye gaze. We have developed a Web browser, GazeTheWeb, that introspects Web page interfaces and adapts both the browser interface and the interaction elements on Web pages for gaze input. In a summative lab study with 20 participants, GazeTheWeb allowed the participants to accomplish information search and browsing tasks significantly faster than an emulation approach. Additional feasibility tests of GazeTheWeb in lab and home environment showcase its effectiveness in accomplishing daily Web browsing activities and adapting large variety of modern Web pages to suffice the interaction for people with motor impairment.}
}

@inproceedings{kumar2019tgp,
 author = {Kumar, Chandan and Akbari, Daniyal and Menges, Raphael and MacKenzie, Scott and Staab, Steffen},
 title = {TouchGazePath: Multimodal Interaction with Touch and Gaze Path for Secure Yet Efficient PIN Entry},
 booktitle = {2019 International Conference on Multimodal Interaction},
 series = {ICMI '19},
 year = {2019},
 isbn = {978-1-4503-6860-5},
 location = {Suzhou, China},
 pages = {329--338},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3340555.3353734},
 doi = {10.1145/3340555.3353734},
 acmid = {3353734},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Authentication, PIN entry, eye tracking, gaze path, multimodal interaction, usable security},
}

@inproceedings{sengupta2019ivp,
 author = {Sengupta, Korok and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
 title = {Impact of Variable Positioning of Text Prediction in Gaze-based Text Entry},
 booktitle = {Proceedings of the 11th ACM Symposium on Eye Tracking Research \& Applications},
 series = {ETRA '19},
 year = {2019},
 isbn = {978-1-4503-6709-7},
 location = {Denver, Colorado},
 pages = {74:1--74:9},
 articleno = {74},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3317956.3318152},
 doi = {10.1145/3317956.3318152},
 acmid = {3318152},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gaze input, interaction, text entry, text prediction, variable position},
}

@inproceedings{sengupta2018hwb,
 author = {Sengupta, Korok and Ke, Min and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
 title = {Hands-free Web Browsing: Enriching the User Experience with Gaze and Voice Modality},
 booktitle = {Proceedings of the 2018 ACM Symposium on Eye Tracking Research \& Applications},
 series = {ETRA '18},
 year = {2018},
 isbn = {978-1-4503-5706-7},
 location = {Warsaw, Poland},
 pages = {88:1--88:3},
 articleno = {88},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/3204493.3208338},
 doi = {10.1145/3204493.3208338},
 acmid = {3208338},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eye tracking, hands-free interaction, multimodal interfaces, speech commands, voice input, web accessibility},
}

@inproceedings{kumar2017cbf,
 author = {Kumar, Chandan and Menges, Raphael and M\"{u}ller, Daniel and Staab, Steffen},
 title = {Chromium Based Framework to Include Gaze Interaction in Web Browser},
 booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
 series = {WWW '17 Companion},
 year = {2017},
 isbn = {978-1-4503-4914-7},
 location = {Perth, Australia},
 pages = {219--223},
 numpages = {5},
 url = {https://doi.org/10.1145/3041021.3054730},
 doi = {10.1145/3041021.3054730},
 acmid = {3054730},
 publisher = {International World Wide Web Conferences Steering Committee},
 address = {Republic and Canton of Geneva, Switzerland},
 keywords = {chromium embedded framework, dom node extraction, eye-controlled interfaces, gaze input, interactive elements, web browser, webpage rendering},
}

@inproceedings{menges2017ggw,
 author = {Menges, Raphael and Kumar, Chandan and M\"{u}ller, Daniel and Sengupta, Korok},
 title = {GazeTheWeb: A Gaze-Controlled Web Browser},
 booktitle = {Proceedings of the 14th Web for All Conference on The Future of Accessible Work},
 series = {W4A '17},
 year = {2017},
 isbn = {978-1-4503-4900-0},
 location = {Perth, Western Australia, Australia},
 pages = {25:1--25:2},
 articleno = {25},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/3058555.3058582},
 doi = {10.1145/3058555.3058582},
 acmid = {3058582},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Web accessibility, Web browser, eye tracking, eye-controlled interfaces, gaze input, navigation},
}

@inproceedings{sengupta2017gik,
 author = {Sengupta, Korok and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
 title = {GazeTheKey: Interactive Keys to Integrate Word Predictions for Gaze-based Text Entry},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 series = {IUI '17 Companion},
 year = {2017},
 isbn = {978-1-4503-4893-5},
 location = {Limassol, Cyprus},
 pages = {121--124},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3030024.3038259},
 doi = {10.1145/3030024.3038259},
 acmid = {3038259},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dwell time, eye tracking, eye typing, gaze input, text entry, visual feedback},
}

@inproceedings{menges2016enf,
 author = {Menges, Raphael and Kumar, Chandan and Sengupta, Korok and Staab, Steffen},
 title = {eyeGUI: A Novel Framework for Eye-Controlled User Interfaces},
 booktitle = {Proceedings of the 9th Nordic Conference on Human-Computer Interaction},
 series = {NordiCHI '16},
 year = {2016},
 isbn = {978-1-4503-4763-1},
 location = {Gothenburg, Sweden},
 pages = {121:1--121:6},
 articleno = {121},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2971485.2996756},
 doi = {10.1145/2971485.2996756},
 acmid = {2996756},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Gaze input, eye tracking, eye-controlled interfaces, interactive elements, visual feedback},
}

@article{kumar2016eim,
 author = {Kumar, Chandan and Menges, Raphael and Staab, Steffen},
 title = {Eye-Controlled Interfaces for Multimedia Interaction},
 journal = {IEEE MultiMedia},
 issue_date = {October 2016},
 volume = {23},
 number = {4},
 month = oct,
 year = {2016},
 issn = {1070-986X},
 pages = {6--13},
 numpages = {8},
 url = {https://doi.org/10.1109/MMUL.2016.52},
 doi = {10.1109/MMUL.2016.52},
 acmid = {3024131},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
}

@inproceedings{menges2018erw,
 author = {Menges, Raphael and Tamimi, Hanadi and Kumar, Chandan and Walber, Tina and Schaefer, Christoph and Staab, Steffen},
 title = {Enhanced Representation of Web Pages for Usability Analysis with Eye Tracking},
 booktitle = {Proceedings of the 2018 ACM Symposium on Eye Tracking Research \& Applications},
 series = {ETRA '18},
 year = {2018},
 isbn = {978-1-4503-5706-7},
 location = {Warsaw, Poland},
 pages = {18:1--18:9},
 articleno = {18},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3204493.3204535},
 doi = {10.1145/3204493.3204535},
 acmid = {3204535},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eye tracking, viewport-relative elements, web page usability},
}

@article{schaefer2014sga,
  address = {Toronto, Canada},
  author = {Schaefer, Christoph and Kuich, Matthias and Menges, Raphael and Schmidt, Kevin and Walber, Tina},
  booktitle = {1st.  Workshop  on  the  Applications  for  Gaze  in Games at CHI Play 2014},
  title = {Schau genau! - an Eye Tracking Game With a Purpose},
  year = 2014
}

@inproceedings{sengupta2017aic, 
  author = {Sengupta, Korok and Sun, Jun and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
  booktitle = {2017 IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title = {Analyzing the Impact of Cognitive Load in Evaluating Gaze-Based Typing}, 
  year = {2017}, 
  pages = {787-792}, 
  keywords = {cognition;electroencephalography;eye;Fourier transforms;gaze tracking;human computer interaction;keyboards;medical signal processing;neurophysiology;user interfaces;text entry performance measures;Gaze-based virtual keyboards;keyboard usability;Short-time Fourier Transform;EEG signal analysis;eye typing usability;word suggestion positioning;eye typing evaluation measure;eye gaze;human brain cognition;natural eye movements;cognitive load;Keyboards;Electroencephalography;Visualization;Layout;eye typing;gaze input;EEG;cognitive load}, 
  doi = {10.1109/CBMS.2017.134}, 
  month = {June},
  publisher = {IEEE},
  volume = {Special Track on Multimodal Interfaces for Natural Human Computer Interaction: Theory and Applications},
}

@inproceedings{menges2017sgc,
  author = {Menges, Raphael and Kumar, Chandan and Wechselberger, Ulrich and Schaefer, Christoph and Walber, Tina and Staab, Steffen},
  booktitle = {Journal of Eye Movement Research},
  eventdate = {21. August 2017},
  eventtitle = {The 2017 COGAIN Symposium},
  issn = {1995-8692},
  number = 6,
  pages = 220,
  title = {Schau genau! A Gaze-Controlled 3D Game for Entertainment and Education},
  venue = {Wuppertal},
  volume = 10,
  year = 2017
}

@inproceedings{kumar2017aug, 
  author= {Kumar, Chandan and Menges, Raphael and Staab, Steffen}, 
  booktitle = {2017 IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title = {Assessing the Usability of Gaze-Adapted Interface against Conventional Eye-Based Input Emulation}, 
  year = {2017}, 
  volume = {Special Track on Multimodal Interfaces for Natural Human Computer Interaction: Theory and Applications},
  publisher = {IEEE},
  pages = {793-798}, 
  keywords={gaze tracking;graphical user interfaces;human computer interaction;human factors;keyboards;mouse controllers (computers);social networking (online);graphical user interface;browser interface;gaze-adapted interface usability assessibility;gaze-adapted Twitter application interface;gaze-based mouse emulation;gaze-based keyboard emulation;subjective user experience;improved user experience;eye gaze input;eye tracking systems;Keyboards;Twitter;Mice;Emulation;Usability;Bars;eye tracking;gaze input;eye-controlled interfaces;social networks;user-centered design;usability analysis}, 
  doi = {10.1109/CBMS.2017.155}, 
  month={June}
}

@article{lichtenberg2018ars,
  author = {Lichtenberg, Nils and Menges, Raphael and Ageev, Vladimir and George, Ajay Abisheck Paul and Heimer, Pascal and Imhof, Diana and Lawonn, Kai},
  doi = {10.1111/cgf.13427},
  issn = {1467-8659},
  journal = {Computer Graphics Forum},
  publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
  title = {Analyzing Residue Surface Proximity to Interpret Molecular Dynamics},
  year = 2018
}
