<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Raphael Menges</title><link href="/css/global.css" rel="stylesheet"><link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"><link rel="manifest" href="/assets/favicon/site.webmanifest"><link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><meta name="google-site-verification" content="m128M0DMnfMFkuzqaUW9xPZWshdGG94WucCt3Q68eSY"><script type="text/javascript" src="/js/lightbox.js"></script></head><body><nav class="navbar"><ul><li><a href="#jobs">Jobs</a></li><li><a href="#academia">Academia</a></li><li><a href="#teaching">Teaching</a></li><li><a href="#software">Software</a></li><li><a href="#arts">Arts</a></li><li><a href="#publications">Publications</a></li></ul></nav><div class="fake-navbar"></div><div class="page"><div class="margin"><div class="profile"><a href="."><img src="../assets/me.jpg"></a><div class="name">Raphael Menges</div><div class="job">Solution Engineer at alfatraining Bildungszentrum GmbH</div><div class="social"><a class="social-github" href="https://github.com/raphaelmenges">GitHub</a> <a class="social-linkedin" href="https://www.linkedin.com/in/raphaelmenges">LinkedIn</a></div></div><button onclick="topFunction()" id="scroll-top" title="to top"><script type="text/javascript">let btn=document.getElementById("scroll-top"),allowToTop=!1;function scrollFunction(){allowToTop=64<document.body.scrollTop||64<document.documentElement.scrollTop?(btn.style.opacity=1,btn.style.cursor="pointer",!0):(btn.style.opacity=0,!(btn.style.cursor="default"))}function topFunction(){allowToTop&&window.scrollTo({top:0,behavior:"smooth"})}window.onscroll=function(){scrollFunction()}</script></div><div class="content" id="content"><span class="greeting">Hi, </span><span class="welcome">I am Raphael Menges from Germany. My interests cover the Web, computer graphics, computer vision, machine learning, and eye tracking.</span><div><a class="anchor" id="jobs"></a><h2>Jobs</h2><div class="timeline"><h3>December 2024 - Today</h3><ol><li><div><strong style="font-variant:small-caps">Solution Engineer</strong>, alfatraining Bildungszentrum GmbH</div><div class="title">New work.<a class="web" href="https://alfaview.com">Web</a><a class="video" href="https://youtu.be/EqVSwaDc83s">Video</a></div><div class="abstract">Bringing edge-ai solutions to products of the alfa corporate group, i.e., the alfaview video conferencing software.</div></li></ol><h3>January 2023 - November 2024</h3><ol><li><div><strong style="font-variant:small-caps">Managing Director</strong>, Semanux GmbH</div><div class="title">Do more. Do it your way.<a class="web" href="https://semanux.com">Web</a></div><div class="abstract">Successful launch of the first product "Semanux Access", a software that enables computer control with alternative inputs means like head tracking, facial expressions, non-verbal speech, buttons, and controllers.</div><div class="note">Founding Date: 11th January 2023</div></li></ol><h3>September 2021 - July 2023</h3><ol><li><div><strong style="font-variant:small-caps">Project Lead</strong>, University of Stuttgart, Institute for Artificial Intelligence</div><div class="title">Semanux EXIST Project<a class="web" href="https://www.ki.uni-stuttgart.de/departments/ac/research/projects/semanux">Web</a></div><div class="abstract">Semanux combines hands-free interaction with artificial intelligence to make the Web inclusive for more people.</div><div class="note">Operating Time: September 2021 - February 2023</div><div class="note">Funding: EXIST Transfer of Research</div></li></ol><h3>April 2021 - August 2021</h3><ol><li><div><strong style="font-variant:small-caps">Scientific Employee</strong>, University of Stuttgart, Institute for Artificial Intelligence</div><div class="title">UDeco Research Project<a class="web" href="https://www.ipvs.uni-stuttgart.de/departments/ac/research/projects/udeco">Web</a></div><div class="abstract">User-friendliness is fundamental for the success of Web applications. User studies help identify problems with Web sites. However, the evaluation of studies by usability experts is time-consuming, highly subjective and so difficult to understand that user studies are often skipped. Hence, many systems remain hard to use. We develop UDeco, a platform for a usability data ecosystem, that collects and processes usability data and knowledge from user studies in order to automate evaluation of usability studies by means of machine learning and data mining.</div><div class="note">Partner: EYEVIDO GmbH</div><div class="note">Operating Time: January 2021 - December 2022</div><div class="note">Funding: KMU-innovativ program by the Federal Ministry of Education and Research of Germany</div></li></ol><h3>December 2016 - March 2021</h3><ol><li><div><strong style="font-variant:small-caps">Project Lead</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">GazeMining Research Project<a class="web" href="http://gazemining.de/index_en.html">Web</a><a class="slides" href="https://www.softwaresysteme.pt-dlr.de/media/content/Projektblatt_GazeMining.pdf">Sheet</a><a class="pdf" href="https://www.tib.eu/en/search/id/TIBKAT:180065426X/KMU-innovativ-Verbundprojekt-GazeMining-Analyse">Report</a></div><div class="abstract">The aim of the research project GazeMining is to capture Web sessions semantically and thus obtain a complete picture of visual content, perception and interaction. The log streams of usability tests are evaluated using data mining. The analysis and interpretability of the data collected in this way is made possible by a user-friendly presentation, semi-automatic and automatic analysis procedures.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("gazemining_poster.jpg","Overview about the GazeMining project.")</script><a href="#" onclick='return showLightbox("gazemining_poster.jpg"),!1'><img src="/assets/imgs/thumbs/gazemining_poster.jpg" title="Overview about the GazeMining project."></a><script type="text/javascript">registerLightboxImage("gazemining_etra.jpg","GazeMining at the 10th ACM Symposium on Eye Tracking Research & Applications, Warsaw, Poland.")</script><a href="#" onclick='return showLightbox("gazemining_etra.jpg"),!1'><img src="/assets/imgs/thumbs/gazemining_etra.jpg" title="GazeMining at the 10th ACM Symposium on Eye Tracking Research & Applications, Warsaw, Poland."></a><script type="text/javascript">registerLightboxImage("gazemining_mittelstandskonferenz.jpg","GazeMining at the Mittelstandskonferenz 2018 in Berlin.")</script><a href="#" onclick='return showLightbox("gazemining_mittelstandskonferenz.jpg"),!1'><img src="/assets/imgs/thumbs/gazemining_mittelstandskonferenz.jpg" title="GazeMining at the Mittelstandskonferenz 2018 in Berlin."></a></div></div><div class="note">Partner: EYEVIDO GmbH</div><div class="note">Operating Time: January 2018 - August 2020</div><div class="note">Funding: KMU-innovativ program by the Federal Ministry of Education and Research of Germany</div></li><li><div><strong style="font-variant:small-caps">Scientific Employee</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">MAMEM Research Project<a class="web" href="http://www.mamem.eu">Web</a><a class="video" href="https://youtu.be/42yGmr3NE0k">Video</a><a class="github" href="https://github.com/MAMEM">GitHub</a></div><div class="abstract">MAMEM's goal is to integrate these people back into society by increasing their potential for communication and exchange in leisure (e.g. social networks) and non-leisure context (e.g. workplace). In this direction, MAMEM delivers the technology to enable interface channels that can be controlled through eye-movements and mental commands. This is accomplished by extending the core API of current operating systems with advanced function calls, appropriate for accessing the signals captured by an eye-tracker, an EEGrecorder and bio-measurement sensors. Then, pattern recognition and tracking algorithms are employed to jointly translate these signals into meaningful control and enable a set of novel paradigms for multimodal interaction. These paradigms will allow for low- (e.g., move a mouse), meso- (e.g., tick a box) and high-level (e.g., select n-out-of-m items) control of interface applications through eyes and mind. A set of persuasive design principles together with profiles modeling the users (dis-)abilities will be also employed for designing adapted interfaces for disabled. MAMEM will engage three different cohorts of disabled (i.e. Parkinson's disease, muscular disorders, and tetraplegia) that will be asked to test a set of prototype applications dealing with multimedia authoring and management. MAMEM's final objective is to assess the impact of this technology in making these people more socially integrated by, for instance, becoming more active in sharing content through social networks and communicating with their friends and family.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("mamem_second_trials.jpg","Picture from the MAMEM Phase 2 trials.")</script><a href="#" onclick='return showLightbox("mamem_second_trials.jpg"),!1'><img src="/assets/imgs/thumbs/mamem_second_trials.jpg" title="Picture from the MAMEM Phase 2 trials."></a><script type="text/javascript">registerLightboxImage("mamem_meeting.jpg","MAMEM Consortium together with its Advisory Board in Thessaloniki, Greece.")</script><a href="#" onclick='return showLightbox("mamem_meeting.jpg"),!1'><img src="/assets/imgs/thumbs/mamem_meeting.jpg" title="MAMEM Consortium together with its Advisory Board in Thessaloniki, Greece."></a></div></div><div class="note">Partners: CERTH - Centre for Research & Technology Hellas, EB Neuro S.p.A (EBN), SMI GmbH, Eindhoven University of Technology (TUe), Muscular Dystrophy Association (MDA) Hellas, Auth - School of Medicine, and Sheba Medical Center (SMC)</div><div class="note">Operating Time: May 2015 - July 2018</div><div class="note">Funding: EU Project Horizon 2020 - The EU Framework Programme for Research and Innovation</div></li></ol><h3>March 2014 - November 2016</h3><ol><li><div><strong style="font-variant:small-caps">Student Assistant</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Software development in Java and C++</div></li></ol><h3>November 2013 - February 2015</h3><ol><li><div><strong style="font-variant:small-caps">Student Assistant</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Corrections of Algorithms and Datastructures assignments</div></li></ol></div></div><div><a class="anchor" id="academia"></a><h2>Academia</h2><div class="timeline"><h3>February 2021</h3><ol><li><div><strong style="font-variant:small-caps">Dr. rer. nat.</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="grade">Grade: magna cum laude (very good)</div><div class="title">Improving Usability and Accessibility of the Web with Eye Tracking <a class="pdf" href="https://kola.opus.hbz-nrw.de/frontdoor/index/index/docId/2205">PDF</a></div><div class="abstract">The Web is an essential component of moving our society to the digital age. We use it for communication, shopping, and doing our work. Most user interaction in the Web happens with Web page interfaces. Thus, the usability and accessibility of Web page interfaces are relevant areas of research to make the Web more useful. Eye tracking is a tool that can be helpful in both areas, performing usability testing and improving accessibility. It can be used to understand users' attention on Web pages and to support usability experts in their decision-making process. Moreover, eye tracking can be used as an input method to control an interface. This is especially useful for people with motor impairment, who cannot use traditional input devices like mouse and keyboard. However, interfaces on Web pages become more and more complex due to dynamics, i.e., changing contents like animated menus and photo carousels. We need general approaches to comprehend dynamics on Web pages, allowing for efficient usability analysis and enjoyable interaction with eye tracking. In the first part of this thesis, we report our work on improving gaze-based analysis of dynamic Web pages. Eye tracking can be used to collect the gaze signals of users, who browse a Web site and its pages. The gaze signals show a usability expert what parts in the Web page interface have been read, glanced at, or skipped. The aggregation of gaze signals allows a usability expert insight into the users' attention on a high-level, before looking into individual behavior. For this, all gaze signals must be aligned to the interface as experienced by the users. However, the user experience is heavily influenced by changing contents, as these may cover a substantial portion of the screen. We delineate unique states in Web page interfaces including changing contents, such that gaze signals from multiple users can be aggregated correctly. In the second part of this thesis, we report our work on improving the gaze-based interaction with dynamic Web pages. Eye tracking can be used to retrieve gaze signals while a user operates a computer. The gaze signals may be interpreted as input controlling an interface. Nowadays, eye tracking as an input method is mostly used to emulate mouse and keyboard functionality, hindering an enjoyable user experience. There exist a few Web browser prototypes that directly interpret gaze signals for control, but they do not work on dynamic Web pages. We have developed a method to extract interaction elements like hyperlinks and text inputs efficiently on Web pages, including changing contents. We adapt the interaction with those elements for eye tracking as the input method, such that a user can conveniently browse the Web hands-free. Both parts of this thesis conclude with user-centered evaluations of our methods, assessing the improvements in the user experience for usability experts and people with motor impairment, respectively.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("phd_cover.jpg","Cover of my dissertation.")</script><a href="#" onclick='return showLightbox("phd_cover.jpg"),!1'><img src="/assets/imgs/thumbs/phd_cover.jpg" title="Cover of my dissertation."></a></div></div><div class="note">Examiner and Supervisor: Prof. Dr. Steffen Staab</div><div class="note">Further Examiners: Prof. Dr. Andreas Bulling and Prof. Dr.-Ing. Dietrich Paulus</div><div class="note">Chair of PhD Board: Prof. Dr. Jan Jürjens</div><div class="note">Chair of PhD Commission: Prof. Dr. Harald F.O. von Korflesch</div></li></ol><h3>October 2016</h3><ol><li><div><strong style="font-variant:small-caps">Master of Science</strong>, University of Koblenz, Computational Visualistics Programme</div><div class="grade">Overall Grade: 1.1 (very good)</div><div class="title">Visualization of Molecule Surface Dynamics <a class="pdf" href="./assets/theses/raphaelmenges_master.pdf">PDF</a><a class="slides" href="/assets/slides/raphaelmenges_master_slides.pdf">Slides</a><a class="github" href="https://github.com/raphaelmenges/MolecularDynamicsVisualization/tree/master/src/executables/SurfaceDynamicsVisualization">GitHub</a></div><div class="grade">Grade: 1.0 (very good)</div><div class="abstract">The surface of a molecule holds important information about the interaction behavior with other molecules. Amino acid residues with different properties change their position within the molecule over time. Some rise up to the surface and contribute to potential bindings. Other descent back into the molecular structure. Surface extraction algorithms are discussed and for the most appropriate one a highly parallel implementation is proposed. Layers of atoms are extracted by an iterative application of the algorithm. This allows one to track residues in their movement within the molecule in respect to their distance to the surface or core. Sampling of the surface is utilized for approximations of further values of interest, like surface area. Novel visualization methods are presented to support scientists in inspection of simulated molecule foldings. Atoms are colored according to their movement activity or an arbitrary group of atoms can be highlighted and analyzed. Proximity of residues to surface or core can be calculated over simulation time and allow conclusions about their contribution.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("master_ui1.jpg","Screenshot of the user interface.")</script><a href="#" onclick='return showLightbox("master_ui1.jpg"),!1'><img src="/assets/imgs/thumbs/master_ui1.jpg" title="Screenshot of the user interface."></a><script type="text/javascript">registerLightboxImage("master_ui2.jpg","Screenshot of the user interface.")</script><a href="#" onclick='return showLightbox("master_ui2.jpg"),!1'><img src="/assets/imgs/thumbs/master_ui2.jpg" title="Screenshot of the user interface."></a><script type="text/javascript">registerLightboxImage("master_surface.jpg","Definition of surface and internal atoms in a molecule.")</script><a href="#" onclick='return showLightbox("master_surface.jpg"),!1'><img src="/assets/imgs/thumbs/master_surface.jpg" title="Definition of surface and internal atoms in a molecule."></a><script type="text/javascript">registerLightboxImage("master_impl.jpg","Pipeline to determine surface of a molecule on a GPU.")</script><a href="#" onclick='return showLightbox("master_impl.jpg"),!1'><img src="/assets/imgs/thumbs/master_impl.jpg" title="Pipeline to determine surface of a molecule on a GPU."></a><script type="text/javascript">registerLightboxImage("master_ascension.jpg","Color-coded visualization of the ascension of a residue.")</script><a href="#" onclick='return showLightbox("master_ascension.jpg"),!1'><img src="/assets/imgs/thumbs/master_ascension.jpg" title="Color-coded visualization of the ascension of a residue."></a></div></div><div class="note">Supervisors: Prof. Dr. Stefan Müller and Nils Lichtenberg, M.Sc.</div></li></ol><h3>March 2014</h3><ol><li><div><strong style="font-variant:small-caps">Bachelor of Science</strong>, University of Koblenz, Computational Visualistics Programme</div><div class="grade">Overall Grade: 1.4 (very good)</div><div class="title">Interactive Ray-Casting of Volume Data (German) <a class="pdf" href="./assets/theses/raphaelmenges_bachelor.pdf">PDF</a><a class="slides" href="/assets/slides/raphaelmenges_bachelor_slides.pdf">Slides</a><a class="github" href="https://github.com/raphaelmenges/Voraca">GitHub</a><a class="video" href="https://youtu.be/sM18a2M5_FM">Video 1</a><a class="video" href="https://youtu.be/ZcDHNtyZ3es">Video 2</a></div><div class="grade">Grade: 1.0 (very good)</div><div class="abstract">This thesis covers the mathematical background of ray-casting as well as an exemplary implementation on graphics processing units, using a modern programming interface. The implementation is embedded within an editor, which enables the user to activate optimizations of the algorithm. Techniques like transfer functions and local illumination are available for a more realistic visualization of materials. Moreover, the user interface gives access to features like importing volumes, let one define a custom transfer function, holds controls to adjust parameters of rendering and allows to activate further techniques, which are also subject of discussion in this thesis. Benefit of all shown techniques is measured, whether it is expected to be visual or on the part of performance.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("bachelor_ui.jpg","Screenshot of the user interface.")</script><a href="#" onclick='return showLightbox("bachelor_ui.jpg"),!1'><img src="/assets/imgs/thumbs/bachelor_ui.jpg" title="Screenshot of the user interface."></a><script type="text/javascript">registerLightboxImage("bachelor_jittering.jpg","Jittering for ray casting.")</script><a href="#" onclick='return showLightbox("bachelor_jittering.jpg"),!1'><img src="/assets/imgs/thumbs/bachelor_jittering.jpg" title="Jittering for ray casting."></a><script type="text/javascript">registerLightboxImage("bachelor_shadows.jpg","Shadows for volume rendering.")</script><a href="#" onclick='return showLightbox("bachelor_shadows.jpg"),!1'><img src="/assets/imgs/thumbs/bachelor_shadows.jpg" title="Shadows for volume rendering."></a><script type="text/javascript">registerLightboxImage("bachelor_transferfunction.jpg","Sampling of transferfunction from a bezier curve.")</script><a href="#" onclick='return showLightbox("bachelor_transferfunction.jpg"),!1'><img src="/assets/imgs/thumbs/bachelor_transferfunction.jpg" title="Sampling of transferfunction from a bezier curve."></a><script type="text/javascript">registerLightboxImage("bachelor_evaluation.jpg","Evaluation of time savings through ray casting improvements.")</script><a href="#" onclick='return showLightbox("bachelor_evaluation.jpg"),!1'><img src="/assets/imgs/thumbs/bachelor_evaluation.jpg" title="Evaluation of time savings through ray casting improvements."></a></div></div><div class="note">Supervisors: Prof. Dr. Stefan Müller and Gerrit Lochmann, M.Sc.</div></li></ol><h3>March 2011</h3><ol><li><div><strong style="font-variant:small-caps">Abitur</strong>, Wilhelm-Hofmann-Gymnasium, St.Goarshausen</div><div>General qualiﬁcation for university entrance. Main subjects were Physics, Maths, and English.</div><div class="grade">Overall Grade: 1.5 (very good)</div></li></ol></div></div><div><a class="anchor" id="teaching"></a><h2>Teaching</h2><div class="timeline"><h3>2016 - 2024</h3><ol><li><div><strong style="font-variant:small-caps">Thesis Supervisor</strong>, University of Stuttgart, Institute for Artificial Intelligence</div><div class="title">Master Thesis: Exploring the dynamics of head pointing<a class="web" href="https://darus.uni-stuttgart.de/dataset.xhtml?persistentId=doi:10.18419/DARUS-4577">Dataset</a></div><div class="note">Student: Georgii Gaziev</div><div class="note">Other Supervisors: Steffen Staab and Mathias Niepert</div></li><li><div><strong style="font-variant:small-caps">Lecturer</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Machine Learning and Data Mining<a class="web" href="https://west.uni-koblenz.de/studying/ws2021/machine-learning-and-data-mining">Web</a></div><div class="abstract">The course Machine Learning and Data Mining (MLDM) covers the fundamentals and basics of machine learning and data mining. The course provides an overview of a variety of MLDM topics and related areas such as clustering and classification.</div><div class="note">Collaborators: Zeyd Boukhers and Tjitze Rienstra</div></li><li><div><strong style="font-variant:small-caps">Lecturer</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Proseminar "Eye Tracking" (German)<a class="web" href="https://west.uni-koblenz.de/studying/ws2021/proseminar-eye-tracking">Web</a></div><div class="note">Other Supervisors: Matthias Thimm</div></li><li><div><strong style="font-variant:small-caps">Tutor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Machine Learning and Data Mining<a class="web" href="https://west.uni-koblenz.de/studying/ws1718/mldm">Winter 17/18</a><a class="web" href="https://west.uni-koblenz.de/studying/ws1819/mldm">Winter 18/19</a><a class="web" href="https://west.uni-koblenz.de/studying/ws1920/machine-learning-and-data-mining">Winter 19/20</a></div><div class="abstract">The master programme course Machine Learning and Data Mining covers the fundamentals and basics of machine learning and data mining. The course provides an overview of a variety of MLDM topics and related areas such as optimization and deep learning.</div><div class="note">Lecturers: Steffen Staab and Zeyd Boukhers</div><div class="note">Collaborators: Qusai Ramadan, Akram Sadat Hosseini, and Mahdi Bohlouli</div></li><li><div><strong style="font-variant:small-caps">Supervisor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Research Lab: Eye Tracking in Word Processing<a class="web" href="https://west.uni-koblenz.de/studying/ss20/research-lab-eye-tracking">Web</a></div><div class="abstract">Exploring the future of word processing with eye tracking.</div><div class="note">Other Supervisors: Matthias Thimm</div></li><li><div><strong style="font-variant:small-caps">Supervisor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Research Lab: Eye Tracking Visualization Platform<a class="web" href="http://eyevis.west.uni-koblenz.de">Web</a><a class="github" href="https://github.com/Shanksum/eyevis-tool">GitHub</a></div><div class="abstract">The platform was created during a research lab project that set the goal to find new ways of visualizing eye tracking data.</div><div class="note">Other Supervisors: Chandan Kumar</div></li><li><div><strong style="font-variant:small-caps">Supervisor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Research Lab: GazeTheWeb - Watch<a class="github" href="https://github.com/MAMEM/GazeTheWeb/tree/master/Watch">GitHub</a></div><div class="abstract">YouTube application controlled with gaze and processing of gaze and EEG sensor data, part of the EU-funded research project MAMEM.</div><div class="note">Other Supervisors: Chandan Kumar and Korok Sengupta</div></li><li><div><strong style="font-variant:small-caps">Supervisor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Research Lab: GazeTheWeb - Tweet<a class="github" href="https://github.com/MAMEM/GazeTheWeb/tree/master/Tweet">GitHub</a></div><div class="abstract">Twitter application controlled with gaze, part of the EU-funded research project MAMEM.</div><div class="note">Other Supervisors: Chandan Kumar and Korok Sengupta</div></li><li><div><strong style="font-variant:small-caps">Thesis Supervisor</strong>, University of Koblenz, Institute for Web Science and Technologies</div><div class="title">Master Thesis: Intelligent Mapping of Eye-Tracking Gaze-Data on Fixed Web Page Elements<a class="pdf" href="https://kola.opus.hbz-nrw.de/frontdoor/index/index/year/2017/docId/1547">PDF</a><a class="github" href="https://github.com/Institute-Web-Science-and-Technologies/MTB">GitHub</a></div><div class="note">Student: Hanadi Tamimi</div><div class="note">Other Supervisors: Steffen Staab and Christoph Schaefer</div><div class="title">Bachelor Thesis: Visualization of Transitions on Web Sites for Usability Studies with Eye Tracking (German)<a class="pdf" href="https://west.uni-koblenz.de/assets/theses/Visualisierung_von_Transitionen_zwischen_und_auf_Webseiten_fuer_Usability-Studien_mit_Eyetracking.pdf">PDF</a><a class="github" href="https://github.com/cbrozmann/PageTransitionThesis">GitHub</a></div><div class="note">Student: Christian Brozmann</div><div class="note">Other Supervisors: Steffen Staab</div><div class="title">Bachelor Thesis: Optical Text Recognition in the Web (German)<a class="pdf" href="https://west.uni-koblenz.de/assets/theses/cdreide_bachelor_thesis.pdf">PDF</a><a class="github" href="https://github.com/Drizzy3D/CGRE">GitHub</a></div><div class="note">Student: Christopher Dreide</div><div class="note">Other Supervisors: Steffen Staab</div><div class="title">Bachelor Thesis: Shot Detection in Screencasts of Web Browsing with Convolutional Neural Networks<a class="pdf" href="https://west.uni-koblenz.de/assets/theses/bachelor-dvossen.pdf">PDF</a><a class="github" href="https://github.com/PommesMitMayo/visual_change_cnn">GitHub</a></div><div class="note">Student: Daniel Vossen</div><div class="note">Other Supervisors: Steffen Staab</div><div class="title">Bachelor Thesis: Semantical Classification of Icons</div><div class="note">Student: Pierre Krapf</div><div class="note">Other Supervisors: Steffen Staab</div></li></ol><h3>2012 - 2015</h3><ol><li><div><strong style="font-variant:small-caps">Tutor</strong>, University of Koblenz, Institute of Arts, Digital Media Group</div><div class="title">Introduction to Blender Game Engine (German) <a class="slides" href="/assets/slides/01-BlenderGameEngine.pdf">Slides 1</a> <a class="slides" href="/assets/slides/02-BlenderGameEngine.pdf">Slides 2</a></div><div class="abstract">Creation of games using the Blender Game Engine.</div></li><li><div><strong style="font-variant:small-caps">Tutor</strong>, University of Koblenz, Institute of Arts, Digital Media Group</div><div class="title">Introduction to Unreal Development Kit (German) <a class="slides" href="/assets/slides/udk_basics.pdf">Slides</a></div><div class="abstract">Level building, materials, visual programming, and particles.</div></li><li><div><strong style="font-variant:small-caps">Tutor</strong>, University of Koblenz, Institute of Arts, Digital Media Group</div><div class="title">Introduction to Game Modeling (German) <a class="slides" href="/assets/slides/01-GameModeling.pdf">Slides 1</a> <a class="slides" href="/assets/slides/02-GameModeling.pdf">Slides 2</a> <a class="slides" href="/assets/slides/03-GameModeling.pdf">Slides 3</a> <a class="slides" href="/assets/slides/04-GameModeling.pdf">Slides 4</a> <a class="slides" href="/assets/slides/05-GameModeling.pdf">Slides 5</a></div><div class="abstract">Modeling, sculpting, painting, and animation for games.</div></li></ol></div></div><div><a class="anchor" id="software"></a><h2>Software</h2><div class="timeline"><h3>Today</h3><ol><li><div><strong style="font-variant:small-caps">GazeTheWeb</strong><a class="github" href="https://github.com/MAMEM/GazeTheWeb">GitHub</a><a class="video" href="https://youtu.be/x1ESgaoQR9Y">Video</a><a class="web" href="https://mamem.github.io/GazeTheWeb">Web</a><a class="slides" href="/assets/slides/gazetheweb.pdf">Slides</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">OpenGL</div><div class="tech-item">JavaScript</div><div class="tech-item">Chromium Embedded Framework</div><div class="tech-item">Google Firebase</div></div><div class="abstract">Gaze-controlled Web browser, part of the EU-funded research project MAMEM. GazeTheWeb effectively supports all common browsing operations like search, navigation and bookmarks. GazeTheWeb is based on a Chromium powered framework,comprising Web extraction to classify interactive elements, and application of gaze interaction paradigms to represent these elements.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("gazetheweb_poster.jpg","Poster about GazeTheWeb.")</script><a href="#" onclick='return showLightbox("gazetheweb_poster.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_poster.jpg" title="Poster about GazeTheWeb."></a><script type="text/javascript">registerLightboxImage("gazetheweb_wikipedia.jpg","GazeTheWeb displaying the Wikipedia homepage.")</script><a href="#" onclick='return showLightbox("gazetheweb_wikipedia.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_wikipedia.jpg" title="GazeTheWeb displaying the Wikipedia homepage."></a><script type="text/javascript">registerLightboxImage("gazetheweb_keyboard.jpg","GazeTheWeb features a multi-language eye-typing keyboard.")</script><a href="#" onclick='return showLightbox("gazetheweb_keyboard.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_keyboard.jpg" title="GazeTheWeb features a multi-language eye-typing keyboard."></a><script type="text/javascript">registerLightboxImage("gazetheweb_tab_overview.jpg","Tab management in GazeTheWeb.")</script><a href="#" onclick='return showLightbox("gazetheweb_tab_overview.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_tab_overview.jpg" title="Tab management in GazeTheWeb."></a><script type="text/javascript">registerLightboxImage("gazetheweb_award.jpg","The team behind GazeThWeb in 2017, holding the W4A Accessibility Award.")</script><a href="#" onclick='return showLightbox("gazetheweb_award.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_award.jpg" title="The team behind GazeThWeb in 2017, holding the W4A Accessibility Award."></a><script type="text/javascript">registerLightboxImage("gazetheweb_tpg.jpg","Annoucement of W4A Accessibility Award for GazeTheWeb.")</script><a href="#" onclick='return showLightbox("gazetheweb_tpg.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_tpg.jpg" title="Annoucement of W4A Accessibility Award for GazeTheWeb."></a><script type="text/javascript">registerLightboxImage("gazetheweb_dichallenge.jpg",'GazeTheWeb scored the third place at the Unitymedia Digital Imagination Challegen in Berlin. Photo by Andi Weiland <a href="https://twitter.com/ohrenflimmern">@ohrenflimmern</a>.')</script><a href="#" onclick='return showLightbox("gazetheweb_dichallenge.jpg"),!1'><img src="/assets/imgs/thumbs/gazetheweb_dichallenge.jpg" title='GazeTheWeb scored the third place at the Unitymedia Digital Imagination Challegen in Berlin. Photo by Andi Weiland <a href="https://twitter.com/ohrenflimmern">@ohrenflimmern</a>.'></a></div></div><div class="people">Collaborators: Daniel Müller, Christopher Dreide, Chandan Kumar, and Steffen Staab</div><div class="award"><span>3rd place at Digital Imagination Challenge</span></div></li><li><div><strong style="font-variant:small-caps">WeST Homepage</strong><a class="web" href="https://west.uni-koblenz.de">Web</a><a class="slides" href="/assets/slides/west.pdf">Slides</a></div><div class="tech-container"><div class="tech-item">Jekyll</div><div class="tech-item">JavaScript</div><div class="tech-item">Docker</div><div class="tech-item">Python</div></div><div class="abstract">Homepage of the Institute for Web Science and Technologies at the University of Koblenz. The entire content is organized in a Git repository as markdown and HTML code. A push to the master branch triggers a continuous integration pipeline, which executes the Jekyll Page Generator within a Docker container and deploys the generated HTML pages to the Web server.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("west_desktop.jpg","Desktop view of the homepage of the Institue for Web Science and Technologies.")</script><a href="#" onclick='return showLightbox("west_desktop.jpg"),!1'><img src="/assets/imgs/thumbs/west_desktop.jpg" title="Desktop view of the homepage of the Institue for Web Science and Technologies."></a><script type="text/javascript">registerLightboxImage("west_mobile.jpg","Mobile view of the homepage of the Institue for Web Science and Technologies.")</script><a href="#" onclick='return showLightbox("west_mobile.jpg"),!1'><img src="/assets/imgs/thumbs/west_mobile.jpg" title="Mobile view of the homepage of the Institue for Web Science and Technologies."></a></div></div><div class="people">Collaborators: Philipp Töws, Adrian Skubella, Danienne Wete, and Daniel Janke</div></li></ol><h3>2020</h3><ol><li><div><strong style="font-variant:small-caps">Visual Stimuli Discovery</strong><a class="github" href="https://github.com/eyevido/visual-stimuli-discovery">GitHub</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">Python</div><div class="tech-item">JavaScript</div><div class="tech-item">OpenCV</div><div class="tech-item">sklearn</div><div class="tech-item">Tesseract</div><div class="tech-item">Shogun ML</div><div class="tech-item">Qt</div></div><div class="abstract">The framework of visual stimuli discovery contains the tools and scrips required to process video and interaction recordings into stimulus shots and visual stimuli.</div><div class="images-scroll"><div class="images"></div></div><div class="people">Collaborators: Christoph Schaefer</div></li></ol><h3>2018</h3><ol><li><div><strong style="font-variant:small-caps">eyeGUI</strong><a class="github" href="https://github.com/raphaelmenges/eyeGUI/tree/development">GitHub</a><a class="video" href="https://youtu.be/niMRX65E7IE">Video</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">OpenGL</div><div class="tech-item">PortAudio</div><div class="tech-item">FreeType 2</div></div><div class="abstract">User interface library for eye-tracking input using C++11 and OpenGL 3.3. eyeGUI supports the development of interactive eye-controlled applications with many significant aspects, like rendering, layout, dynamic modification of content, support of graphics, and animation.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("eyegui_architecture.jpg","Architecture of eyeGUI library.")</script><a href="#" onclick='return showLightbox("eyegui_architecture.jpg"),!1'><img src="/assets/imgs/thumbs/eyegui_architecture.jpg" title="Architecture of eyeGUI library."></a><script type="text/javascript">registerLightboxImage("eyegui_flow.jpg","How to integrate eyeGUI into an application.")</script><a href="#" onclick='return showLightbox("eyegui_flow.jpg"),!1'><img src="/assets/imgs/thumbs/eyegui_flow.jpg" title="How to integrate eyeGUI into an application."></a><script type="text/javascript">registerLightboxImage("eyegui_twitter.jpg","Gaze-controlled Twitter application using eyeGUI for handling the interface.")</script><a href="#" onclick='return showLightbox("eyegui_twitter.jpg"),!1'><img src="/assets/imgs/thumbs/eyegui_twitter.jpg" title="Gaze-controlled Twitter application using eyeGUI for handling the interface."></a><script type="text/javascript">registerLightboxImage("eyegui_web.jpg","An very early version of GazeTheWeb, which is using eyeGUI for the gaze-controlled interface.")</script><a href="#" onclick='return showLightbox("eyegui_web.jpg"),!1'><img src="/assets/imgs/thumbs/eyegui_web.jpg" title="An very early version of GazeTheWeb, which is using eyeGUI for the gaze-controlled interface."></a></div></div></li></ol><h3>2016</h3><ol><li><div><strong style="font-variant:small-caps">Voxel Cone Tracing</strong><a class="github" href="https://github.com/raphaelmenges/VoxelConeTracingAO">GitHub</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">OpenGL</div><div class="tech-item">CUDA</div></div><div class="abstract">Final project for the course ‘Realtime Rendering’. A polygonial scene is voxelized in real-time through geometry and pixel shading. The voxel grid is transferred to CUDA, where Voxel Cone Tracing is implemented to compute ambient occlusion and global illuminatin. My part of the project was the efficient voxelization of the scene.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("voxel_color.jpg","Voxel Cone Tracing.")</script><a href="#" onclick='return showLightbox("voxel_color.jpg"),!1'><img src="/assets/imgs/thumbs/voxel_color.jpg" title="Voxel Cone Tracing."></a><script type="text/javascript">registerLightboxImage("voxel_ao.jpg","Voxel Cone Tracing.")</script><a href="#" onclick='return showLightbox("voxel_ao.jpg"),!1'><img src="/assets/imgs/thumbs/voxel_ao.jpg" title="Voxel Cone Tracing."></a><script type="text/javascript">registerLightboxImage("voxel_bounce.jpg","Voxel Cone Tracing.")</script><a href="#" onclick='return showLightbox("voxel_bounce.jpg"),!1'><img src="/assets/imgs/thumbs/voxel_bounce.jpg" title="Voxel Cone Tracing."></a></div></div><div class="people">Collaborators: Fabian Meyer, Milan Dilberovic, and Nils Höhner</div></li></ol><h3>2015</h3><ol><li><div><strong style="font-variant:small-caps">Beer Heater</strong><a class="github" href="https://github.com/raphaelmenges/BeerHeater">GitHub</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">OpenGL</div><div class="tech-item">Compute Shaders</div></div><div class="abstract">Project about simulating air flow and heat distribution for the course ‘Animation and Simulation’ at the University of Koblenz in the summer term 2015. The simulation is executed with highly parallel compute shader computations.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("beer_heater_example.jpg","Physically-based simulation of air flow and heat distribution.")</script><a href="#" onclick='return showLightbox("beer_heater_example.jpg"),!1'><img src="/assets/imgs/thumbs/beer_heater_example.jpg" title="Physically-based simulation of air flow and heat distribution."></a><script type="text/javascript">registerLightboxImage("beer_heater_cooler.jpg","Physically-based simulation of air flow and heat distribution.")</script><a href="#" onclick='return showLightbox("beer_heater_cooler.jpg"),!1'><img src="/assets/imgs/thumbs/beer_heater_cooler.jpg" title="Physically-based simulation of air flow and heat distribution."></a></div></div><div class="people">Collaborators: Nils Höhner</div></li><li><div><strong style="font-variant:small-caps">Schau genau!</strong><a class="github" href="https://github.com/raphaelmenges/schaugenau">GitHub</a><a class="video" href="https://youtu.be/WOcb94t6BaQ">Video</a><a class="web" href="https://raphaelmenges.github.io/schaugenau">Web</a></div><div class="tech-container"><div class="tech-item">Java</div><div class="tech-item">JMonkey</div><div class="tech-item">Blender</div></div><div class="abstract">Schau genau! was designed for the State Horticultural Show Landau 2015 as arcarde box game, using only gaze and one buzzer as input. Nearly 3000 sessions were played during the summer without any downtime. I have used Java and the jMonkey engine as programming framework and Blender to create the assets.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("schaugenau_intro.jpg","Idle screen of Schau genau!")</script><a href="#" onclick='return showLightbox("schaugenau_intro.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_intro.jpg" title="Idle screen of Schau genau!"></a><script type="text/javascript">registerLightboxImage("schaugenau_tutorial.jpg","Tutorial of Schau genau!")</script><a href="#" onclick='return showLightbox("schaugenau_tutorial.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_tutorial.jpg" title="Tutorial of Schau genau!"></a><script type="text/javascript">registerLightboxImage("schaugenau_butterfly.jpg","The avatar in Schau genau!")</script><a href="#" onclick='return showLightbox("schaugenau_butterfly.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_butterfly.jpg" title="The avatar in Schau genau!"></a><script type="text/javascript">registerLightboxImage("schaugenau_gameplay.jpg","Gameplay of Schau genau!")</script><a href="#" onclick='return showLightbox("schaugenau_gameplay.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_gameplay.jpg" title="Gameplay of Schau genau!"></a><script type="text/javascript">registerLightboxImage("schaugenau_highscore.jpg","Name for the highscore table can be entered via eye gaze.")</script><a href="#" onclick='return showLightbox("schaugenau_highscore.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_highscore.jpg" title="Name for the highscore table can be entered via eye gaze."></a><script type="text/javascript">registerLightboxImage("schaugenau_box.jpg","Arcade box with Schau genau!")</script><a href="#" onclick='return showLightbox("schaugenau_box.jpg"),!1'><img src="/assets/imgs/thumbs/schaugenau_box.jpg" title="Arcade box with Schau genau!"></a></div></div><div class="people">Collaborators: Kevin Schmidt</div></li></ol><h3>2014</h3><ol><li><div><strong style="font-variant:small-caps">Voraca</strong><a class="github" href="https://github.com/raphaelmenges/Voraca">GitHub</a></div><div class="tech-container"><div class="tech-item">C++</div><div class="tech-item">OpenGL</div></div><div class="abstract">Versatile tool to visualize volumes with GPU ray-casting. I have written the tool as part of my bachelor thesis. It allows to load abitrary volume data sets with density information. A transferfunction can be adjusted to map density values to color, opacity, and shading attributes like specular reflection. The ray-casting has been written as pixel shader and improved through stochastic jitterin, early ray termination, and empty space skipping.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("voraca_ui.jpg","User interface of Voraca.")</script><a href="#" onclick='return showLightbox("voraca_ui.jpg"),!1'><img src="/assets/imgs/thumbs/voraca_ui.jpg" title="User interface of Voraca."></a><script type="text/javascript">registerLightboxImage("voraca_cube.jpg","User interface of Voraca.")</script><a href="#" onclick='return showLightbox("voraca_cube.jpg"),!1'><img src="/assets/imgs/thumbs/voraca_cube.jpg" title="User interface of Voraca."></a><script type="text/javascript">registerLightboxImage("voraca_bucky_ball.jpg","User interface of Voraca.")</script><a href="#" onclick='return showLightbox("voraca_bucky_ball.jpg"),!1'><img src="/assets/imgs/thumbs/voraca_bucky_ball.jpg" title="User interface of Voraca."></a><script type="text/javascript">registerLightboxImage("voraca_brain.jpg","User interface of Voraca.")</script><a href="#" onclick='return showLightbox("voraca_brain.jpg"),!1'><img src="/assets/imgs/thumbs/voraca_brain.jpg" title="User interface of Voraca."></a></div></div></li></ol></div></div><div><a class="anchor" id="arts"></a><h2>Arts</h2><div class="timeline"><h3>2011 - 2016</h3><ol><li><div><strong style="font-variant:small-caps">Artist</strong>, University of Koblenz, Institute of Arts, Digital Media Group<div class="title">Voxelmania. Effects of Videogames on Service Robots <a class="video" href="https://youtu.be/">Video</a> <a class="web" href="http://shortfilms.rosfilmfestival.com/video/8lcx9facybsl">Web</a></div><div class="abstract">We are proud to present our short film "Voxelmania. Effects of Videogames on Service Robots". The main actor is LISA. She is our Star and also an award winning service robot in different international contests (supported by team homer@university koblenz-landau, campus Koblenz). In a crossover of dream and reality LISA is exploring the world of video games.</div><div class="note">Course: Open space course of summer term 2016 by Markus Lohoff</div><div class="note">Collaborators: Julien Rodewald, Markus Lohoff, and 15 further students</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, University of Koblenz, Institute of Computational Visualistics, Computer Graphics Group<div class="title">Ship happens! - A 3ds Max Movie <a class="video" href="https://youtu.be/pq4D2nC8EJM">Video</a></div><div class="abstract">Small lighthouse is short of sleep...</div><div class="note">Course: 3ds Max course of winter term 2013/2014 by Sebastian Pohl</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("ship_1.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_1.png"),!1'><img src="/assets/imgs/thumbs/ship_1.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("ship_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_2.png"),!1'><img src="/assets/imgs/thumbs/ship_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("ship_3.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_3.png"),!1'><img src="/assets/imgs/thumbs/ship_3.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("ship_4.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_4.png"),!1'><img src="/assets/imgs/thumbs/ship_4.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("ship_5.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_5.png"),!1'><img src="/assets/imgs/thumbs/ship_5.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("ship_6.png","Artwork.")</script><a href="#" onclick='return showLightbox("ship_6.png"),!1'><img src="/assets/imgs/thumbs/ship_6.png" title="Artwork."></a></div></div><div class="note">Collaborators: Adrian Derstroff, Raphael Heidrich, Dominik Cremer and Saner Demirel</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, University of Koblenz, Institute of Arts, Digital Media Group<div class="title">Steoreo - A Blender Movie <a class="video" href="https://youtu.be/qlkXId7oDqU">Video</a> <a class="web" href="/archive/steoreo">Web</a></div><div class="abstract">What are the benefits for visual perception that having two eyes brings with it? Which sensations can be artificially generated? To find out, it's two robots task to work through an experimental series that highlights some aspects of the problem.</div><div class="note">Course: Aspects of image design of summer term 2011 by Markus Lohoff</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("steoreo_poster.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_poster.jpg"),!1'><img src="/assets/imgs/thumbs/steoreo_poster.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("steoreo_1.png","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_1.png"),!1'><img src="/assets/imgs/thumbs/steoreo_1.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("steoreo_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_2.png"),!1'><img src="/assets/imgs/thumbs/steoreo_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("steoreo_3.png","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_3.png"),!1'><img src="/assets/imgs/thumbs/steoreo_3.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("steoreo_4.png","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_4.png"),!1'><img src="/assets/imgs/thumbs/steoreo_4.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("steoreo_5.png","Artwork.")</script><a href="#" onclick='return showLightbox("steoreo_5.png"),!1'><img src="/assets/imgs/thumbs/steoreo_5.png" title="Artwork."></a></div></div><div class="note">Collaborators: Arend Buchacher and Michael Taenzer</div></div></li></ol><h3>2008 - 2014</h3><ol><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">JustHotAir - A puzzle-action-game for Windows <a class="web" href="https://www.indiedb.com/games/just-hot-air">Web</a> <a class="web" href="https://www.microsoft.com/en-us/p/just-hot-air/9wzdncrdf5nl">Microsoft Store</a> <a class="video" href="https://youtu.be/cyeSko84DLk">Video 1</a> <a class="video" href="https://youtu.be/0toRJ-5JBpk">Video 2</a> <a class="video" href="https://youtu.be/xI1WAQnuY58">Video 3</a></div><div class="abstract">Little creatures need your help! Save them by kicking them into the lit hole and make use of the environment to use less kicks. Each kick increases the inner pressure of the creature: One kick over limit and it explodes like a balloon filled with too much hot air.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("jha_logo.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_logo.png"),!1'><img src="/assets/imgs/thumbs/jha_logo.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_ingame_1.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_ingame_1.png"),!1'><img src="/assets/imgs/thumbs/jha_ingame_1.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_ingame_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_ingame_2.png"),!1'><img src="/assets/imgs/thumbs/jha_ingame_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_ingame_3.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_ingame_3.png"),!1'><img src="/assets/imgs/thumbs/jha_ingame_3.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_ingame_4.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_ingame_4.png"),!1'><img src="/assets/imgs/thumbs/jha_ingame_4.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_gameplay.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_gameplay.png"),!1'><img src="/assets/imgs/thumbs/jha_gameplay.png" title="Artwork."></a></div></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("jha_1.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_1.png"),!1'><img src="/assets/imgs/thumbs/jha_1.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_2.png"),!1'><img src="/assets/imgs/thumbs/jha_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_3.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_3.png"),!1'><img src="/assets/imgs/thumbs/jha_3.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_4.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_4.png"),!1'><img src="/assets/imgs/thumbs/jha_4.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_5.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_5.png"),!1'><img src="/assets/imgs/thumbs/jha_5.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_6.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_6.png"),!1'><img src="/assets/imgs/thumbs/jha_6.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_7.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_7.png"),!1'><img src="/assets/imgs/thumbs/jha_7.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_8.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_8.png"),!1'><img src="/assets/imgs/thumbs/jha_8.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_9.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_9.png"),!1'><img src="/assets/imgs/thumbs/jha_9.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("jha_10.png","Artwork.")</script><a href="#" onclick='return showLightbox("jha_10.png"),!1'><img src="/assets/imgs/thumbs/jha_10.png" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien and Michael Taenzer</div><div class="award">10.000 downloads in Windows Phone Store</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">Pulsedrive - A music-driven racing game <a class="web" href="https://www.indiedb.com/games/pulsedrive">Web</a> <a class="video" href="https://youtu.be/DHoG2mTCdXY">Video 1</a> <a class="video" href="https://youtu.be/9it-8XIv4g4">Video 2</a></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("pulsedrive_1.png","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_1.png"),!1'><img src="/assets/imgs/thumbs/pulsedrive_1.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("pulsedrive_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_2.png"),!1'><img src="/assets/imgs/thumbs/pulsedrive_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("pulsedrive_3.png","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_3.png"),!1'><img src="/assets/imgs/thumbs/pulsedrive_3.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("pulsedrive_4.png","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_4.png"),!1'><img src="/assets/imgs/thumbs/pulsedrive_4.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("pulsedrive_5.png","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_5.png"),!1'><img src="/assets/imgs/thumbs/pulsedrive_5.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("pulsedrive_6.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("pulsedrive_6.jpg"),!1'><img src="/assets/imgs/thumbs/pulsedrive_6.jpg" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">Beyond Jupiter - A role-playing hack and slash game <a class="web" href="https://www.indiedb.com/games/beyondjupiter">Web</a> <a class="slides" href="/assets/docs/beyondjupiter.pdf">Game Design</a></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("bj_1.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_1.jpg"),!1'><img src="/assets/imgs/thumbs/bj_1.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("bj_2.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_2.jpg"),!1'><img src="/assets/imgs/thumbs/bj_2.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("bj_3.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_3.jpg"),!1'><img src="/assets/imgs/thumbs/bj_3.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("bj_4.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_4.jpg"),!1'><img src="/assets/imgs/thumbs/bj_4.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("bj_7.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_7.jpg"),!1'><img src="/assets/imgs/thumbs/bj_7.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("bj_8.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("bj_8.jpg"),!1'><img src="/assets/imgs/thumbs/bj_8.jpg" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">Demos for the [w]tech engine by Andre Taulien <a class="web" href="https://www.indiedb.com/engines/wtech">Web</a> <a class="video" href="https://youtu.be/441it3a37rg">Video 1</a> <a class="video" href="https://youtu.be/FZB_zOE4164">Video 2</a> <a class="video" href="https://youtu.be/y6ZwfIKYmL8">Video 3</a> <a class="video" href="https://youtu.be/48MM9zzMxRM">Video 4</a> <a class="video" href="https://youtu.be/utgdDmSTOO0">Video 5</a></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("wtech_1.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_1.jpg"),!1'><img src="/assets/imgs/thumbs/wtech_1.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_2.png","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_2.png"),!1'><img src="/assets/imgs/thumbs/wtech_2.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_4.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_4.jpg"),!1'><img src="/assets/imgs/thumbs/wtech_4.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_5.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_5.jpg"),!1'><img src="/assets/imgs/thumbs/wtech_5.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_6.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_6.jpg"),!1'><img src="/assets/imgs/thumbs/wtech_6.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_7.png","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_7.png"),!1'><img src="/assets/imgs/thumbs/wtech_7.png" title="Artwork."></a><script type="text/javascript">registerLightboxImage("wtech_8.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("wtech_8.jpg"),!1'><img src="/assets/imgs/thumbs/wtech_8.jpg" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">Tre - Last Life <a class="web" href="https://www.moddb.com/mods/tre-last-life">Web</a> <a class="video" href="https://youtu.be/IuRDzZau3lc">Video 1</a> <a class="video" href="https://youtu.be/R3wFlC-urUs">Video 2</a></div><div class="abstract">Total conversion of Unreal Tournament 3</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("tre2_poster.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_poster.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_poster.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre2_environment.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_environment.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_environment.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre2_fire.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_fire.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_fire.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre2_underwater.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_underwater.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_underwater.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre2_dev.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_dev.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_dev.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre2_menu.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre2_menu.jpg"),!1'><img src="/assets/imgs/thumbs/tre2_menu.jpg" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien and Mr.Tom</div><div class="award">$1 Million Intel "Make Something Unreal" Contest Phase 4 Finalist</div></div></li><li><div><strong style="font-variant:small-caps">Artist</strong>, Personal Activity<div class="title">Tre - The Spreading <a class="web" href="https://www.moddb.com/mods/tre-the-spreading">Web</a> <a class="video" href="https://www.moddb.com/mods/tre-the-spreading/videos/trailer-1">Video</a></div><div class="abstract">Total conversion of Unreal Tournament 3</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("tre1_home.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre1_home.jpg"),!1'><img src="/assets/imgs/thumbs/tre1_home.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre1_lava.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre1_lava.jpg"),!1'><img src="/assets/imgs/thumbs/tre1_lava.jpg" title="Artwork."></a><script type="text/javascript">registerLightboxImage("tre1_stream.jpg","Artwork.")</script><a href="#" onclick='return showLightbox("tre1_stream.jpg"),!1'><img src="/assets/imgs/thumbs/tre1_stream.jpg" title="Artwork."></a></div></div><div class="note">Collaborators: Andre Taulien</div></div></li></ol></div></div><div><a class="anchor" id="publications"></a><h2>Publications</h2><div class="intro">I have published my research in international conferences, like ACM ETRA and ACM WWW, and ACM Transactions on Computer-Human Interaction. I have also reviewed submissions for ACM ETRA, ACM UIST, and ACM CHI.</div><div class="timeline"><h3 class="bibliography">2023</h3><ol class="bibliography"><li><div class="reference"><span id="hedeshy2023cnvve"><span style="font-variant:small-caps">Hedeshy, R., Menges, R., and Staab, S.</span> 2023. CNVVE: Dataset and Benchmark for Classifying Non-verbal Voice. <i>Proceedings of INTERSPEECH 2023</i>, 1553–1557.</span></div><a class="pdf" href="/assets/pubs/hedeshy2023cnvve.pdf">PDF</a><a class="doi" href="https://doi.org/10.21437/Interspeech.2023-201">DOI</a><a class="details" href="/bibliography/hedeshy2023cnvve/">BibTeX</a></li></ol><h3 class="bibliography">2021</h3><ol class="bibliography"><li><div class="reference"><span id="hedeshy2021hummer"><span style="font-variant:small-caps">Hedeshy, R., Kumar, C., Menges, R., and Staab, S.</span> 2021. Hummer: Text Entry by Gaze and Hum. <i>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</i>, Association for Computing Machinery.</span></div><a class="pdf" href="/assets/pubs/hedeshy2021hummer.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3411764.3445501">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/9781450380966">ISBN</a><a class="video" href="https://youtu.be/_eu91g5fTaw">Video</a><a class="details" href="/bibliography/hedeshy2021hummer/">BibTeX</a></li></ol><h3 class="bibliography">2020</h3><ol class="bibliography"><li><div class="reference"><span id="hedeshy2020giuplayer"><span style="font-variant:small-caps">Hedeshy, R., Kumar, C., Menges, R., and Staab, S.</span> 2020. GIUPlayer: A Gaze Immersive YouTube Player Enabling Eye Control and Attention Analysis. <i>ACM Symposium on Eye Tracking Research and Applications</i>, Association for Computing Machinery.</span></div><a class="pdf" href="/assets/pubs/hedeshy2020giuplayer.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3379157.3391984">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/9781450371353">ISBN</a><a class="details" href="/bibliography/hedeshy2020giuplayer/">BibTeX</a></li><li><div class="reference"><span id="kumar2020mamem"><span style="font-variant:small-caps">Kumar, C., Menges, R., Sengupta, K., and Staab, S.</span> 2020. Eye tracking for Interaction: Evaluation Methods. In: S. Nikolopoulos, C. Kumar and I. Kompatsiaris, eds., <i>Signal Processing to Drive Human-Computer Interaction: EEG and eye-controlled interfaces</i>. Institution of Engineering and Technology, 117–144.</span></div><a class="doi" href="https://doi.org/10.1049/PBCE129E_ch6">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/9781785619199">ISBN</a><a class="details" href="/bibliography/kumar2020mamem/">BibTeX</a></li><li><div class="reference"><span id="menges2020mamem"><span style="font-variant:small-caps">Menges, R., Kumar, C., and Staab, S.</span> 2020. Eye tracking for Interaction: Adapting Multimedia Interfaces. In: S. Nikolopoulos, C. Kumar and I. Kompatsiaris, eds., <i>Signal Processing to Drive Human-Computer Interaction: EEG and eye-controlled interfaces</i>. Institution of Engineering and Technology, 83–116.</span></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("iet_book.jpg","")</script><a href="#" onclick='return showLightbox("iet_book.jpg"),!1'><img src="/assets/imgs/thumbs/iet_book.jpg" title=""></a></div></div><a class="doi" href="https://doi.org/10.1049/PBCE129E_ch5">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/9781785619199">ISBN</a><a class="details" href="/bibliography/menges2020mamem/">BibTeX</a></li><li><div class="reference"><span id="menges2020vistool"><span style="font-variant:small-caps">Menges, R., Kramer, S., Hill, S., Nisslmueller, M., Kumar, C., and Staab, S.</span> 2020. A Visualization Tool for Eye Tracking Data Analysis in the Web. <i>ACM Symposium on Eye Tracking Research and Applications</i>, Association for Computing Machinery.</span></div><a class="pdf" href="/assets/pubs/menges2020vistool.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3379156.3391831">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/9781450371346">ISBN</a><a class="details" href="/bibliography/menges2020vistool/">BibTeX</a></li></ol><h3 class="bibliography">2019</h3><ol class="bibliography"><li><div class="reference"><span id="menges2019iue"><span style="font-variant:small-caps">Menges, R., Kumar, C., and Staab, S.</span> 2019. Improving User Experience of Eye Tracking-Based Interaction: Introspecting and Adapting Interfaces. <i>ACM Trans. Comput.-Hum. Interact.</i> <i>26</i>, 6, 37:1–37:46.</span></div><div class="abstract">Eye tracking systems have greatly improved in recent years, being a viable and affordable option as digital communication channel, especially for people lacking fine motor skills. Using eye tracking as an input method is challenging due to accuracy and ambiguity issues, and therefore research in eye gaze interaction is mainly focused on better pointing and typing methods. However, these methods eventually need to be assimilated to enable users to control application interfaces. A common approach to employ eye tracking for controlling application interfaces is to emulate mouse and keyboard functionality. We argue that the emulation approach incurs unnecessary interaction and visual overhead for users, aggravating the entire experience of gaze-based computer access. We discuss how the knowledge about the interface semantics can help reducing the interaction and visual overhead to improve the user experience. Thus, we propose the efficient introspection of interfaces to retrieve the interface semantics and adapt the interaction with eye gaze. We have developed a Web browser, GazeTheWeb, that introspects Web page interfaces and adapts both the browser interface and the interaction elements on Web pages for gaze input. In a summative lab study with 20 participants, GazeTheWeb allowed the participants to accomplish information search and browsing tasks significantly faster than an emulation approach. Additional feasibility tests of GazeTheWeb in lab and home environment showcase its effectiveness in accomplishing daily Web browsing activities and adapting large variety of modern Web pages to suffice the interaction for people with motor impairment.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("iue_pd.jpg","A photo from the MAMEM trials. Aparticipant with Parkinson&#39s disease selects an E-Mail. Photographer: Tasos Papazoglou-Chalikias. Centre for Research & Technology Hellas - Information Technologies Institute.")</script><a href="#" onclick='return showLightbox("iue_pd.jpg"),!1'><img src="/assets/imgs/thumbs/iue_pd.jpg" title="A photo from the MAMEM trials. Aparticipant with Parkinson&#39s disease selects an E-Mail. Photographer: Tasos Papazoglou-Chalikias. Centre for Research & Technology Hellas - Information Technologies Institute."></a><script type="text/javascript">registerLightboxImage("iue_web_extraction.jpg","Data flow for real-time interaction element classification and tracking. In the example, a text input is added dynamically to the DOM tree of the Web page via an AJAX execution.")</script><a href="#" onclick='return showLightbox("iue_web_extraction.jpg"),!1'><img src="/assets/imgs/thumbs/iue_web_extraction.jpg" title="Data flow for real-time interaction element classification and tracking. In the example, a text input is added dynamically to the DOM tree of the Web page via an AJAX execution."></a><script type="text/javascript">registerLightboxImage("iue_keyboard_hebrew.jpg","GazeTheWeb has been localized to meet the constraints of the field study. The localization not only includes the screen texts of the interface but also the available keyboard layouts and text editing facilities.")</script><a href="#" onclick='return showLightbox("iue_keyboard_hebrew.jpg"),!1'><img src="/assets/imgs/thumbs/iue_keyboard_hebrew.jpg" title="GazeTheWeb has been localized to meet the constraints of the field study. The localization not only includes the screen texts of the interface but also the available keyboard layouts and text editing facilities."></a><script type="text/javascript">registerLightboxImage("iue_youtube.jpg","Shows the hours of different participants on YouTube videopages. Hereby, &#39Watching&#39 is the time the eye-tracking device had detected the participant in front of the screen; &#39Foreground&#39 is the time the video has been visible but the participant has been absent; &#39Background&#39 is the time another tab had been chosen visible.")</script><a href="#" onclick='return showLightbox("iue_youtube.jpg"),!1'><img src="/assets/imgs/thumbs/iue_youtube.jpg" title="Shows the hours of different participants on YouTube videopages. Hereby, &#39Watching&#39 is the time the eye-tracking device had detected the participant in front of the screen; &#39Foreground&#39 is the time the video has been visible but the participant has been absent; &#39Background&#39 is the time another tab had been chosen visible."></a></div></div><a class="pdf" href="https://dl.acm.org/authorize?N690524">PDF</a><a class="doi" href="https://doi.org/10.1145/3338844">DOI</a><a class="details" href="/bibliography/menges2019iue/">BibTeX</a></li><li><div class="reference"><span id="kumar2019tgp"><span style="font-variant:small-caps">Kumar, C., Akbari, D., Menges, R., MacKenzie, S., and Staab, S.</span> 2019. TouchGazePath: Multimodal Interaction with Touch and Gaze Path for Secure Yet Efficient PIN Entry. <i>2019 International Conference on Multimodal Interaction</i>, ACM, 329–338.</span></div><a class="pdf" href="/assets/pubs/kumar2019tgp.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3340555.3353734">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-6860-5">ISBN</a><a class="video" href="https://youtu.be/dWWD1fVMAi0">Video</a><a class="details" href="/bibliography/kumar2019tgp/">BibTeX</a></li><li><div class="reference"><span id="sengupta2019ivp"><span style="font-variant:small-caps">Sengupta, K., Menges, R., Kumar, C., and Staab, S.</span> 2019. Impact of Variable Positioning of Text Prediction in Gaze-based Text Entry. <i>Proceedings of the 11th ACM Symposium on Eye Tracking Research &amp; Applications</i>, ACM, 74:1–74:9.</span></div><a class="pdf" href="/assets/pubs/sengupta2019ivp.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3317956.3318152">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-6709-7">ISBN</a><a class="details" href="/bibliography/sengupta2019ivp/">BibTeX</a></li></ol><h3 class="bibliography">2018</h3><ol class="bibliography"><li><div class="reference"><span id="lichtenberg2018ars"><span style="font-variant:small-caps">Lichtenberg, N., Menges, R., Ageev, V., et al.</span> 2018. Analyzing Residue Surface Proximity to Interpret Molecular Dynamics. <i>Computer Graphics Forum</i>.</span></div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("ars_overview.jpg","From an input molecule (left), we derive a surface proximity term (center, left) that represents the closeness of an atom to the molecule surface. We apply this method to a Molecular Dynamics simulation to obtain a color-coded map, representing the trajectory for each atom or residue (center). Single time-steps can be visualized in 3D (right), e.g., VdW-spheres or in a combined backbone-helix form.")</script><a href="#" onclick='return showLightbox("ars_overview.jpg"),!1'><img src="/assets/imgs/thumbs/ars_overview.jpg" title="From an input molecule (left), we derive a surface proximity term (center, left) that represents the closeness of an atom to the molecule surface. We apply this method to a Molecular Dynamics simulation to obtain a color-coded map, representing the trajectory for each atom or residue (center). Single time-steps can be visualized in 3D (right), e.g., VdW-spheres or in a combined backbone-helix form."></a><script type="text/javascript">registerLightboxImage("ars_example.jpg","Link between RSP-map (top, showing one residue) and 3D-view (center). The highlighted residue (inverted colors) is part of the core until 39ns (center, left). It then emerges for a short period (center) before going back to the core after 48ns (center, right). Information per atom can also be obtained in a detail view (bottom). A tracker (top, red bar) selects a time-step from the RSP-map.")</script><a href="#" onclick='return showLightbox("ars_example.jpg"),!1'><img src="/assets/imgs/thumbs/ars_example.jpg" title="Link between RSP-map (top, showing one residue) and 3D-view (center). The highlighted residue (inverted colors) is part of the core until 39ns (center, left). It then emerges for a short period (center) before going back to the core after 48ns (center, right). Information per atom can also be obtained in a detail view (bottom). A tracker (top, red bar) selects a time-step from the RSP-map."></a></div></div><a class="doi" href="https://doi.org/10.1111/cgf.13427">DOI</a><a class="details" href="/bibliography/lichtenberg2018ars/">BibTeX</a></li><li><div class="reference"><span id="menges2018erw"><span style="font-variant:small-caps">Menges, R., Tamimi, H., Kumar, C., Walber, T., Schaefer, C., and Staab, S.</span> 2018. Enhanced Representation of Web Pages for Usability Analysis with Eye Tracking. <i>Proceedings of the 2018 ACM Symposium on Eye Tracking Research &amp; Applications</i>, ACM, 18:1–18:9.</span></div><div class="abstract">Eye tracking as a tool to quantify user attention plays a major role in research and application design. For Web page usability, it has become a prominent measure to assess which sections of a Web page are read, glanced or skipped. Such assessments primarily depend on the mapping of gaze data to a Web page representation. However, current representation methods, a virtual screenshot of the Web page or a video recording of the complete interaction session, suffer either from accuracy or scalability issues. We present a method that identifies fixed elements on Web pages and combines user viewport screenshots in relation to fixed elements for an enhanced representation of the page. We conducted an experiment with 10 participants and the results signify that analysis with our method is more efficient than a video recording, which is an essential criterion for large scale Web studies.</div><div class="images-scroll"><div class="images"><script type="text/javascript">registerLightboxImage("erw_problems.jpg","Problems P1 to P3 of the virtual screenshot as Web page representation. The actual experience of the users on the Web page is visualized on the left. The corresponding virtual screenshot is shown on the right.")</script><a href="#" onclick='return showLightbox("erw_problems.jpg"),!1'><img src="/assets/imgs/thumbs/erw_problems.jpg" title="Problems P1 to P3 of the virtual screenshot as Web page representation. The actual experience of the users on the Web page is visualized on the left. The corresponding virtual screenshot is shown on the right."></a><script type="text/javascript">registerLightboxImage("erw_enhanced_representation.jpg","The enhanced representation of the visual Web page content for attention analysis.")</script><a href="#" onclick='return showLightbox("erw_enhanced_representation.jpg"),!1'><img src="/assets/imgs/thumbs/erw_enhanced_representation.jpg" title="The enhanced representation of the visual Web page content for attention analysis."></a><script type="text/javascript">registerLightboxImage("erw_screenshot.jpg","Enhanced representation of the Creative-commons.org Web page with scan paths from evaluation.")</script><a href="#" onclick='return showLightbox("erw_screenshot.jpg"),!1'><img src="/assets/imgs/thumbs/erw_screenshot.jpg" title="Enhanced representation of the Creative-commons.org Web page with scan paths from evaluation."></a></div></div><div class="award"><span>Best Video Award (for accompanying video)</span></div><a class="pdf" href="/assets/pubs/menges2018erw.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3204493.3204535">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-5706-7">ISBN</a><a class="video" href="https://youtu.be/SXLE9xM5P2c">Video</a><a class="slides" href="/assets/slides/menges2018erw.pdf">Slides</a><a class="details" href="/bibliography/menges2018erw/">BibTeX</a></li><li><div class="reference"><span id="sengupta2018hwb"><span style="font-variant:small-caps">Sengupta, K., Ke, M., Menges, R., Kumar, C., and Staab, S.</span> 2018. Hands-free Web Browsing: Enriching the User Experience with Gaze and Voice Modality. <i>Proceedings of the 2018 ACM Symposium on Eye Tracking Research &amp; Applications</i>, ACM, 88:1–88:3.</span></div><a class="pdf" href="/assets/pubs/sengupta2018hwb.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3204493.3208338">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-5706-7">ISBN</a><a class="video" href="https://youtu.be/M0hHakm36y0">Video</a><a class="details" href="/bibliography/sengupta2018hwb/">BibTeX</a></li></ol><h3 class="bibliography">2017</h3><ol class="bibliography"><li><div class="reference"><span id="kumar2017aug"><span style="font-variant:small-caps">Kumar, C., Menges, R., and Staab, S.</span> 2017. Assessing the Usability of Gaze-Adapted Interface against Conventional Eye-Based Input Emulation. <i>2017 IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)</i>, IEEE, 793–798.</span></div><a class="pdf" href="/assets/pubs/kumar2017aug.pdf">PDF</a><a class="doi" href="https://doi.org/10.1109/CBMS.2017.155">DOI</a><a class="video" href="https://youtu.be/NQQfB7nf3qw">Video</a><a class="slides" href="/assets/slides/kumar2017aug.pdf">Slides</a><a class="details" href="/bibliography/kumar2017aug/">BibTeX</a></li><li><div class="reference"><span id="sengupta2017aic"><span style="font-variant:small-caps">Sengupta, K., Sun, J., Menges, R., Kumar, C., and Staab, S.</span> 2017. Analyzing the Impact of Cognitive Load in Evaluating Gaze-Based Typing. <i>2017 IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)</i>, IEEE, 787–792.</span></div><div class="award"><span>Best Student Paper Award</span></div><a class="pdf" href="/assets/pubs/sengupta2017aic.pdf">PDF</a><a class="doi" href="https://doi.org/10.1109/CBMS.2017.134">DOI</a><a class="details" href="/bibliography/sengupta2017aic/">BibTeX</a></li><li><div class="reference"><span id="kumar2017cbf"><span style="font-variant:small-caps">Kumar, C., Menges, R., Müller, D., and Staab, S.</span> 2017. Chromium Based Framework to Include Gaze Interaction in Web Browser. <i>Proceedings of the 26th International Conference on World Wide Web Companion</i>, International World Wide Web Conferences Steering Committee, 219–223.</span></div><div class="award"><span>Honourable Mention</span></div><a class="pdf" href="/assets/pubs/kumar2017cbf.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3041021.3054730">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-4914-7">ISBN</a><a class="details" href="/bibliography/kumar2017cbf/">BibTeX</a></li><li><div class="reference"><span id="menges2017ggw"><span style="font-variant:small-caps">Menges, R., Kumar, C., Müller, D., and Sengupta, K.</span> 2017. GazeTheWeb: A Gaze-Controlled Web Browser. <i>Proceedings of the 14th Web for All Conference on The Future of Accessible Work</i>, ACM, 25:1–25:2.</span></div><div class="award"><span>Judges Award at TPG Accessibility Challenge</span></div><a class="pdf" href="/assets/pubs/menges2017ggw.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3058555.3058582">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-4900-0">ISBN</a><a class="video" href="https://youtu.be/x1ESgaoQR9Y">Video</a><a class="details" href="/bibliography/menges2017ggw/">BibTeX</a></li><li><div class="reference"><span id="menges2017sgc"><span style="font-variant:small-caps">Menges, R., Kumar, C., Wechselberger, U., Schaefer, C., Walber, T., and Staab, S.</span> 2017. Schau genau! A Gaze-Controlled 3D Game for Entertainment and Education. <i>Journal of Eye Movement Research</i>, 220.</span></div><a class="pdf" href="/assets/pubs/menges2017sgc.pdf">PDF</a><a class="video" href="https://youtu.be/WOcb94t6BaQ">Video</a><a class="details" href="/bibliography/menges2017sgc/">BibTeX</a></li><li><div class="reference"><span id="sengupta2017gik"><span style="font-variant:small-caps">Sengupta, K., Menges, R., Kumar, C., and Staab, S.</span> 2017. GazeTheKey: Interactive Keys to Integrate Word Predictions for Gaze-based Text Entry. <i>Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion</i>, ACM, 121–124.</span></div><a class="pdf" href="/assets/pubs/sengupta2017gik.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/3030024.3038259">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-4893-5">ISBN</a><a class="video" href="https://youtu.be/-UDDTJHBPVA">Video</a><a class="details" href="/bibliography/sengupta2017gik/">BibTeX</a></li></ol><h3 class="bibliography">2016</h3><ol class="bibliography"><li><div class="reference"><span id="kumar2016eim"><span style="font-variant:small-caps">Kumar, C., Menges, R., and Staab, S.</span> 2016. Eye-Controlled Interfaces for Multimedia Interaction. <i>IEEE MultiMedia</i> <i>23</i>, 4, 6–13.</span></div><a class="doi" href="https://doi.org/10.1109/MMUL.2016.52">DOI</a><a class="details" href="/bibliography/kumar2016eim/">BibTeX</a></li><li><div class="reference"><span id="menges2016enf"><span style="font-variant:small-caps">Menges, R., Kumar, C., Sengupta, K., and Staab, S.</span> 2016. eyeGUI: A Novel Framework for Eye-Controlled User Interfaces. <i>Proceedings of the 9th Nordic Conference on Human-Computer Interaction</i>, ACM, 121:1–121:6.</span></div><a class="pdf" href="/assets/pubs/menges2016enf.pdf">PDF</a><a class="doi" href="https://doi.org/10.1145/2971485.2996756">DOI</a><a class="isbn" href="https://isbnsearch.org/isbn/978-1-4503-4763-1">ISBN</a><a class="video" href="https://youtu.be/niMRX65E7IE">Video</a><a class="details" href="/bibliography/menges2016enf/">BibTeX</a></li></ol><h3 class="bibliography">2014</h3><ol class="bibliography"><li><div class="reference"><span id="schaefer2014sga"><span style="font-variant:small-caps">Schaefer, C., Kuich, M., Menges, R., Schmidt, K., and Walber, T.</span> 2014. Schau genau! - an Eye Tracking Game With a Purpose. <i>1st. Workshop on the Applications for Gaze in Games at CHI Play 2014</i>.</span></div><a class="pdf" href="/assets/pubs/schaefer2014sga.pdf">PDF</a><a class="video" href="https://youtu.be/nB6fQ-310lg">Video</a><a class="details" href="/bibliography/schaefer2014sga/">BibTeX</a></li></ol></div><script type="text/javascript">let elems=document.getElementsByClassName("reference"),regex=new RegExp("Menges, R.","g");Array.prototype.forEach.call(elems,function(e){e.innerHTML=e.innerHTML.replace(regex,e=>`<strong>${e}</strong>`)})</script></div></div></div><div class="footer">© Raphael Menges 2025</div><script type="text/javascript" src="/js/abstract.js"></script></body></html>